{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Image_Classifier_Animal_Train_Model_01.ipynb is too slow.\n",
    "# It would take 90 hr to finish so I will optimize in this notebook instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split train test\n",
    "Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validate(original_images_base_path: str, augmented_images_base_path: str, animals: List[str]) -> Tuple[List[str], List[str], List[str]]:\n",
    "    all_images = []\n",
    "\n",
    "    # Loop through each animal type and gather images from both original and augmented directories\n",
    "    for animal in animals:\n",
    "        original_images_path = os.path.join(original_images_base_path, animal)\n",
    "        #augmented_images_path = os.path.join(augmented_images_base_path, animal)\n",
    "\n",
    "        # Use glob to collect all images of this type of animal from both directories\n",
    "        original_images = glob.glob(os.path.join(original_images_path, '*.jpg'))  # Adjust the pattern if needed\n",
    "        #augmented_images = glob.glob(os.path.join(augmented_images_path, '*.jpeg'))  # Adjust the pattern if needed\n",
    "\n",
    "        all_images.extend(original_images)\n",
    "        #all_images.extend(augmented_images)\n",
    "\n",
    "    # Splitting the dataset into training, validation, and test sets\n",
    "    train_val_images, test_images = train_test_split(all_images, test_size=0.2, random_state=42)  # 20% for testing\n",
    "    train_images, val_images = train_test_split(train_val_images, test_size=0.125, random_state=42)  # 12.5% of 80% = 10% for validation\n",
    "\n",
    "    print(f\"Total images: {len(all_images)}\")\n",
    "    print(f\"Training set size: {len(train_images)}\")\n",
    "    print(f\"Validation set size: {len(val_images)}\")\n",
    "    print(f\"Test set size: {len(test_images)}\")\n",
    "\n",
    "    return train_images, val_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, train_generator, validation_generator, epochs):\n",
    "    \n",
    "    filepath=\"model_{epoch:02d}_{val_accuracy:.2f}.h5\"\n",
    "    model_dir = r'C:\\Users\\purin\\Desktop\\ImageClassifier-Animal\\ImageClassifier-Animal\\models'\n",
    "    model_save_path = os.path.join(model_dir, filepath)\n",
    "    os.makedirs(os.path.dirname(model_dir), exist_ok=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=(epochs//10) +1,  \n",
    "        restore_best_weights=True  \n",
    "    )\n",
    "    \n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath= model_save_path,\n",
    "        save_best_only= True,\n",
    "        monitor= 'val_accuracy',\n",
    "        mode='max',\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "        epochs= epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.n // validation_generator.batch_size\n",
    "        callbacks= [early_stopping, model_checkpoint_callback]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(output_directory,image_list) :\n",
    "    with open(output_directory, 'w') as file :\n",
    "        for item in image_list:\n",
    "            file.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, layer_name, input_image):\n",
    "    model = Model(inputs=model.inputs, outputs=model.get_layer(layer_name).output)\n",
    "    feature_maps = model.predict(input_image)\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(1, feature_maps.shape[-1] + 1):\n",
    "        plt.subplot(6, 6, i)\n",
    "        plt.imshow(feature_maps[0, :, :, i-1], cmap='viridis')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(original_images_directory:str, augmented_images_directory:str, train_test_valid_directory:str,epochs:int):\n",
    "\n",
    "    animals = [\n",
    "    \"antelope\", \"badger\", \"bat\", \"bear\", \"bee\", \"beetle\", \"bison\", \"boar\", \"butterfly\",\n",
    "    \"cat\", \"caterpillar\", \"chimpanzee\", \"cockroach\", \"cow\", \"coyote\", \"crab\", \"crow\", \"deer\",\n",
    "    \"dog\", \"dolphin\", \"donkey\", \"dragonfly\", \"duck\", \"eagle\", \"elephant\", \"flamingo\", \"fly\",\n",
    "    \"fox\", \"goat\", \"goldfish\", \"goose\", \"gorilla\", \"grasshopper\", \"hamster\", \"hare\", \"hedgehog\",\n",
    "    \"hippopotamus\", \"hornbill\", \"horse\", \"hummingbird\", \"hyena\", \"jellyfish\", \"kangaroo\",\n",
    "    \"koala\", \"ladybugs\", \"leopard\", \"lion\", \"lizard\", \"lobster\", \"mosquito\", \"moth\", \"mouse\",\n",
    "    \"octopus\", \"okapi\", \"orangutan\", \"otter\", \"owl\", \"ox\", \"oyster\", \"panda\", \"parrot\",\n",
    "    \"pelecaniformes\", \"penguin\", \"pig\", \"pigeon\", \"porcupine\", \"possum\", \"raccoon\", \"rat\",\n",
    "    \"reindeer\", \"rhinoceros\", \"sandpiper\", \"seahorse\", \"seal\", \"shark\", \"sheep\", \"snake\",\n",
    "    \"sparrow\", \"squid\", \"squirrel\", \"starfish\", \"swan\", \"tiger\", \"turkey\", \"turtle\", \"whale\",\n",
    "    \"wolf\", \"wombat\", \"woodpecker\", \"zebra\"\n",
    "    ]\n",
    "    \n",
    "\n",
    "    train_images, test_images, val_images = train_test_validate(original_images_directory, augmented_images_directory, animals)\n",
    "    train_images, val_images = shuffle(train_images), shuffle(val_images)\n",
    "    \n",
    "\n",
    "    train_text_path = os.path.join(train_test_valid_directory, 'train.txt')\n",
    "    test_text_path = os.path.join(train_test_valid_directory, 'test.txt')\n",
    "    validate_text_path = os.path.join(train_test_valid_directory, 'validate.txt')\n",
    "    save_text(train_text_path,train_images)\n",
    "    save_text(test_text_path,test_images)\n",
    "    save_text(validate_text_path,val_images)\n",
    "    \n",
    "    \n",
    "    train_df = pd.DataFrame({\n",
    "        'filename': train_images,\n",
    "        'class': [os.path.basename(os.path.dirname(x)) for x in train_images] \n",
    "    })\n",
    "    val_df = pd.DataFrame({\n",
    "        'filename': val_images,\n",
    "        'class': [os.path.basename(os.path.dirname(x)) for x in val_images]\n",
    "    })\n",
    "\n",
    "   \n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "   \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'  \n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical' \n",
    "    )\n",
    "    \n",
    "  \n",
    "    num_classes = train_df['class'].nunique()\n",
    "    model = create_model((224, 224, 3), num_classes)\n",
    "    plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "   \n",
    "    history = compile_and_train(model, train_generator, validation_generator, epochs)\n",
    "    plot_training_history(history)\n",
    "   \n",
    "    model.save('animal_classifier_model.h5')\n",
    "\n",
    "   \n",
    "    print(history.history['accuracy'])\n",
    "    print(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 5400\n",
      "Training set size: 3780\n",
      "Validation set size: 540\n",
      "Test set size: 1080\n",
      "Found 3780 validated image filenames belonging to 90 classes.\n",
      "Found 1080 validated image filenames belonging to 90 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "118/118 [==============================] - 209s 2s/step - loss: 4.4441 - accuracy: 0.0264 - val_loss: 4.2692 - val_accuracy: 0.0540\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 168s 1s/step - loss: 4.1128 - accuracy: 0.0846 - val_loss: 3.9972 - val_accuracy: 0.1108\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 168s 1s/step - loss: 3.4102 - accuracy: 0.2241 - val_loss: 3.7147 - val_accuracy: 0.1866\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 170s 1s/step - loss: 2.1652 - accuracy: 0.4832 - val_loss: 3.9269 - val_accuracy: 0.2652\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 168s 1s/step - loss: 1.1344 - accuracy: 0.7201 - val_loss: 4.5175 - val_accuracy: 0.3040\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 167s 1s/step - loss: 0.5905 - accuracy: 0.8655 - val_loss: 5.2170 - val_accuracy: 0.3087\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 167s 1s/step - loss: 0.3459 - accuracy: 0.9234 - val_loss: 6.1820 - val_accuracy: 0.2955\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 179s 2s/step - loss: 0.2566 - accuracy: 0.9464 - val_loss: 5.8465 - val_accuracy: 0.3134\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 128s 1s/step - loss: 0.1691 - accuracy: 0.9610 - val_loss: 6.4805 - val_accuracy: 0.3059\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 124s 1s/step - loss: 0.1845 - accuracy: 0.9602 - val_loss: 5.7178 - val_accuracy: 0.3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\purin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.026414087042212486, 0.08457843959331512, 0.22411952912807465, 0.48319104313850403, 0.7201173901557922, 0.8655282855033875, 0.9234258532524109, 0.9463713765144348, 0.9610459208488464, 0.9602454900741577]\n",
      "[0.053977273404598236, 0.11079545319080353, 0.18655303120613098, 0.2651515007019043, 0.30397728085517883, 0.3087121248245239, 0.2954545319080353, 0.313446968793869, 0.30587121844291687, 0.3219696879386902]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(\n",
    "        r'C:\\Users\\purin\\Desktop\\ImageClassifier-Animal\\ImageClassifier-Animal\\data\\animal_dataset\\animals\\animals',\n",
    "        r'C:\\Users\\purin\\Desktop\\ImageClassifier-Animal\\ImageClassifier-Animal\\data\\augmented_images',\n",
    "        r'C:\\Users\\purin\\Desktop\\ImageClassifier-Animal\\ImageClassifier-Animal\\data\\train_test_validate',\n",
    "        20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
